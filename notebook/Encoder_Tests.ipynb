{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from dataset import get_labelled, get_unlabelled, _preload\n",
    "from Commit import CommitFactory\n",
    "from Model import CommitDiffModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 16\n",
    "BAG_SIZE = 512\n",
    "OUTPUT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commit = CommitFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)\n",
    "CommitDiffModel = CommitDiffModelFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE, OUTPUT_SIZE=OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Commit lookup table\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32a43fc21454e259a49c3835cdc14c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../data/commit_lookups/supervised_commit_data_lookup0-1000.pickle\n",
      "Appending pickle of length: 184 , new dict length: 184\n",
      "Loading file ../data/commit_lookups/commit_data_lookup12500-15000.pickle\n",
      "Appending pickle of length: 2497 , new dict length: 2681\n",
      "Loading file ../data/commit_lookups/commit_data_lookup10000-12500.pickle\n",
      "Appending pickle of length: 2496 , new dict length: 5177\n"
     ]
    }
   ],
   "source": [
    "_preload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679b9a45d4d7428e9fdf71e6253f0204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Positive X_train:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0452fae224fa4ef6bdd864e6197e7c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Positive y_train:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7eba879f3b4530afe6ed1334370ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negative X_train:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1acf27c8764202b1d5c9745f6c1b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negative y_train:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_labelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a4453547344b508d8e691d11635ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Unsupervised X_train:   0%|          | 0/5177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_unsupervised = get_unlabelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size 132\n",
      "Train set split 0.5833333333333334\n",
      "Test set size 33\n",
      "Test set split 0.5454545454545454\n",
      "Unsupervised Train Size 5177\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size\", len(y_train))\n",
    "print(\"Train set split\", np.sum(y_train)/len(y_train))\n",
    "print(\"Test set size\", len(y_test))\n",
    "print(\"Test set split\", np.sum(y_test)/len(y_test))\n",
    "print(\"Unsupervised Train Size\", len(X_train_unsupervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/brennan/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "81/81 [==============================] - 6s 36ms/step - loss: -0.5112\n",
      "3/3 [==============================] - 7s 48ms/step - loss: 0.8546\n"
     ]
    }
   ],
   "source": [
    "debug = CommitDiffModel()\n",
    "debug.initialize(encoder=0)\n",
    "debug.fit_siam(np.array(X_train_unsupervised), epochs=1, batch_size=64, verbose=1)\n",
    "debug.fit_binary_classification(X_train, np.array(y_train), epochs=1, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded1: tf.Tensor(\n",
      "[[ 0.5313834   0.31119585 -0.40491328  0.22323953 -0.9756087  -1.3600199\n",
      "   1.2041396  -0.7061452   0.07178355  0.3344193  -0.01434582  0.35798025\n",
      "   1.2776144   0.9289185   1.163372   -0.68175316  0.79743826 -0.42700344\n",
      "   0.5562434   0.48803836 -0.21568955  0.45876527 -0.47208247 -0.45189223\n",
      "  -0.6977732  -0.68747723  0.31950048  0.4046296  -0.14091158 -0.4077265\n",
      "  -0.91834944 -0.41066644 -0.45000833 -0.93571633 -0.48524076 -0.43913317\n",
      "  -0.66083956 -0.48078325 -0.08665306  0.05938193 -0.87294376  0.48737195\n",
      "  -0.73684     0.7643501  -0.3570439   0.94443005 -0.24262922 -0.2797534\n",
      "   0.05649977 -0.3166979  -0.2671985   0.669685   -0.60511714  0.00990672\n",
      "  -0.98669547  0.9271621  -0.27688527  0.4719644  -0.17257495  0.34804717\n",
      "  -0.47625577 -0.95920277  0.28417453 -0.0234936   0.45645216 -0.6497511\n",
      "  -0.19192824  0.17270252  0.19320747 -0.08592993 -0.17439823  0.03072764\n",
      "  -0.02064663 -0.22217181  0.07262839  0.35823387 -0.3924521  -0.6320791\n",
      "  -0.5909932   0.73460853  0.9330912   0.16925403 -0.5964972  -0.06146035\n",
      "  -0.95198005  0.16106229 -0.06796287 -0.08932977 -0.4320238  -0.747162\n",
      "  -0.28205013 -0.2822006  -0.00402543  0.37409633  0.1726556  -0.19336993\n",
      "   0.21995649  0.55965304 -0.92475504  0.39054665  0.04471739  0.27306354\n",
      "  -0.38497928 -0.88444555  0.59388775  0.41921726 -0.60687757  0.07325693\n",
      "  -1.0341282   0.80136853 -0.26296932  1.0092568  -0.32984486 -0.19104287\n",
      "  -0.4524494   0.8162731  -0.12445166  0.6342386   0.08487882  0.00995528\n",
      "  -0.58271646 -0.67395234  0.06314255 -1.1552283   0.29040942 -1.0373212\n",
      "   0.4155027  -0.07417749]], shape=(1, 128), dtype=float32)\n",
      "Encoded2: tf.Tensor(\n",
      "[[ 3.71834695e-01  3.49122167e-01 -3.40322912e-01  1.93852678e-01\n",
      "  -8.87460113e-01 -1.33667493e+00  1.15752304e+00 -6.50030971e-01\n",
      "  -2.97686085e-02  2.44902819e-01  1.00480527e-01  3.46015245e-01\n",
      "   1.20918179e+00  1.00104928e+00  1.21931076e+00 -6.43484116e-01\n",
      "   8.74519467e-01 -4.76663947e-01  5.80449343e-01  4.58603650e-01\n",
      "  -1.23616867e-01  4.51675117e-01 -3.74617964e-01 -3.65089178e-01\n",
      "  -6.95191979e-01 -7.07047701e-01  2.55119294e-01  4.85975116e-01\n",
      "  -1.19985744e-01 -5.43075264e-01 -8.45057249e-01 -3.92841190e-01\n",
      "  -4.68246400e-01 -8.23092580e-01 -4.40679073e-01 -4.11199063e-01\n",
      "  -6.46147251e-01 -5.11745572e-01 -9.96734574e-02  1.00093633e-01\n",
      "  -9.63909626e-01  5.42714834e-01 -6.57613993e-01  7.66188264e-01\n",
      "  -4.93405104e-01  9.70326900e-01 -3.34349096e-01 -3.25722069e-01\n",
      "   6.33506998e-02 -2.28447288e-01 -3.87706548e-01  5.79115868e-01\n",
      "  -4.44547176e-01  3.40516418e-02 -1.00710738e+00  8.32938135e-01\n",
      "  -2.60006666e-01  4.58539814e-01 -1.60758570e-01  5.09026408e-01\n",
      "  -4.31939095e-01 -9.85653996e-01  3.07875842e-01 -8.18623230e-04\n",
      "   4.32343096e-01 -6.07440054e-01 -1.51804596e-01  7.25441948e-02\n",
      "   4.28258255e-02 -2.41355430e-02 -6.26593679e-02 -2.62761656e-02\n",
      "  -5.92409968e-02 -3.15996766e-01  3.67098860e-02  4.51233506e-01\n",
      "  -5.22202730e-01 -7.50737131e-01 -5.90937555e-01  6.58975542e-01\n",
      "   8.48906875e-01  7.48971179e-02 -6.79310918e-01 -6.05966821e-02\n",
      "  -8.44591796e-01  2.41303653e-01  7.50673003e-04 -1.60953328e-01\n",
      "  -4.85725284e-01 -6.13498390e-01 -2.57342011e-01 -2.00583294e-01\n",
      "  -1.23432860e-01  3.77482772e-01  2.21249878e-01 -9.65178609e-02\n",
      "   1.44012749e-01  4.54903305e-01 -9.01099503e-01  3.80927473e-01\n",
      "   1.60303086e-01  1.95199177e-01 -4.73091453e-01 -7.75853395e-01\n",
      "   5.83342910e-01  3.62836987e-01 -5.87676167e-01  5.20332716e-02\n",
      "  -9.37532008e-01  8.40757489e-01 -2.24111572e-01  9.19557631e-01\n",
      "  -2.90506989e-01 -1.79654449e-01 -5.90202570e-01  8.06690574e-01\n",
      "  -3.31582651e-02  5.08510709e-01  4.51380834e-02 -2.14501172e-02\n",
      "  -6.06539369e-01 -5.81826866e-01 -3.73741165e-02 -1.07263911e+00\n",
      "   3.90073210e-01 -1.10734046e+00  3.78801554e-01 -1.14346571e-01]], shape=(1, 128), dtype=float32)\n",
      "1\n",
      "1.0\n",
      "[0.777143   1.         0.99966465]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'reshape' (type Reshape).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: reshape/strided_slice/\n\nCall arguments received by layer 'reshape' (type Reshape):\n  • inputs=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mdebug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "File \u001b[0;32m~/474CommitML/notebook/Model.py:485\u001b[0m, in \u001b[0;36mCommitDiffModelFactory.<locals>.CommitDiffModel.debug\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_timestamp[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_message[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 485\u001b[0m name_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_name\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m timestamp_reshaped \u001b[38;5;241m=\u001b[39m Reshape((\u001b[38;5;241m1\u001b[39m,))((X_train_timestamp[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    487\u001b[0m message_reshaped \u001b[38;5;241m=\u001b[39m Reshape((\u001b[38;5;241m1\u001b[39m,))((X_train_message[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'reshape' (type Reshape).\n\n{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: reshape/strided_slice/\n\nCall arguments received by layer 'reshape' (type Reshape):\n  • inputs=1"
     ]
    }
   ],
   "source": [
    "output = debug.debug(X_train)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1af822781f449fb6e745c8df5350ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "21/21 [==============================] - 3s 96ms/step - loss: -0.3797\n",
      "Epoch 2/4\n",
      "21/21 [==============================] - 2s 80ms/step - loss: -0.5845\n",
      "Epoch 3/4\n",
      "21/21 [==============================] - 2s 88ms/step - loss: -0.6319\n",
      "Epoch 4/4\n",
      "21/21 [==============================] - 2s 83ms/step - loss: -0.6629\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model_5/concatenate_1/ConcatOffset' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2452314/2795671995.py\", line 5, in <module>\n      model.fit_binary_classification(X_train, np.array(y_train), epochs=8, batch_size=32, verbose=1)\n    File \"/home/brennan/474CommitML/notebook/Model.py\", line 449, in fit_binary_classification\n      self.binary_classification_model.fit(\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/model_5/concatenate_1/ConcatOffset'\nAll dimensions except 1 must match. Input 2 has shape [32 1] and doesn't match input 0 with shape [1024 128].\n\t [[{{node gradient_tape/model_5/concatenate_1/ConcatOffset}}]] [Op:__inference_train_function_19180]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39minitialize(encoder)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit_siam(np\u001b[38;5;241m.\u001b[39marray(X_train_unsupervised), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_binary_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate_binary_classification(X_test, np\u001b[38;5;241m.\u001b[39marray(y_test), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnocder:\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoder)\n",
      "File \u001b[0;32m~/474CommitML/notebook/Model.py:449\u001b[0m, in \u001b[0;36mCommitDiffModelFactory.<locals>.CommitDiffModel.fit_binary_classification\u001b[0;34m(self, X_train, y_train, epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m    446\u001b[0m X_train_bag1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tup[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m X_train])\n\u001b[1;32m    447\u001b[0m X_train_bag2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tup[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tup \u001b[38;5;129;01min\u001b[39;00m X_train])\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_classification_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_timestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_bag1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_bag2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_5/concatenate_1/ConcatOffset' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/brennan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/brennan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2452314/2795671995.py\", line 5, in <module>\n      model.fit_binary_classification(X_train, np.array(y_train), epochs=8, batch_size=32, verbose=1)\n    File \"/home/brennan/474CommitML/notebook/Model.py\", line 449, in fit_binary_classification\n      self.binary_classification_model.fit(\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/home/brennan/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/model_5/concatenate_1/ConcatOffset'\nAll dimensions except 1 must match. Input 2 has shape [32 1] and doesn't match input 0 with shape [1024 128].\n\t [[{{node gradient_tape/model_5/concatenate_1/ConcatOffset}}]] [Op:__inference_train_function_19180]"
     ]
    }
   ],
   "source": [
    "for encoder in tqdm([6,7,8,9,10,11,1,2,3,4]):\n",
    "    model = CommitDiffModel()\n",
    "    model.initialize(encoder)\n",
    "    model.fit_siam(np.array(X_train_unsupervised), epochs=4, batch_size=256, verbose=1)\n",
    "    model.fit_binary_classification(X_train, np.array(y_train), epochs=8, batch_size=32, verbose=1)\n",
    "    score = model.evaluate_binary_classification(X_test, np.array(y_test), verbose=0)\n",
    "    print(\"Enocder:\", encoder)\n",
    "    print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
