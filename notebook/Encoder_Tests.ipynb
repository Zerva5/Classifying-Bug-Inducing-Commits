{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmayall/Documents/School/T2Y4/SENG474/Project/474CommitML/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['OMP_NUM_THREADS'] = '3' \n",
    "os.environ['KMP_BLOCKTIME'] = '1'\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "from dataset import get_labelled, get_unlabelled, _preload, _unload, unlabelled_generator\n",
    "from Commit import CommitFactory\n",
    "from Model import CommitDiffModelFactory\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 16\n",
    "BAG_SIZE = 256\n",
    "OUTPUT_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commit = CommitFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)\n",
    "CommitDiffModel = CommitDiffModelFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE, OUTPUT_SIZE=OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Commit lookup table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading commit lookups:   0%|          | 0/32768 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../data/commit_lookups/labelled/01_priority_commit_lookups.pickle\n"
     ]
    }
   ],
   "source": [
    "_preload(max_commit_bag_size = 2048, max_commits = 4096*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_labelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unsupervised = get_unlabelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set size\", len(y_train))\n",
    "print(\"Train set split\", np.sum(y_train)/len(y_train))\n",
    "print(\"Test set size\", len(y_test))\n",
    "print(\"Test set split\", np.sum(y_test)/len(y_test))\n",
    "print(\"Unsupervised Train Size\", len(X_train_unsupervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Unsupervised X_train:   0%|          | 0/184 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer \"gradient_accumulate_model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(256, 16), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[39m=\u001b[39m CommitDiffModel(unsupervised_data_size \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39minitialize(encoder\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model\u001b[39m.\u001b[39;49mfit_siam_generator(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/School/T2Y4/SENG474/Project/474CommitML/notebook/Model.py:478\u001b[0m, in \u001b[0;36mCommitDiffModelFactory.<locals>.CommitDiffModel.fit_siam_generator\u001b[0;34m(self, generator, epochs, verbose)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_siam_generator\u001b[39m(\u001b[39mself\u001b[39m, generator, epochs, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):   \n\u001b[0;32m--> 478\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msiam_model\u001b[39m.\u001b[39;49mfit(generator, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49mverbose, callbacks\u001b[39m=\u001b[39;49mClearMemory())\n",
      "File \u001b[0;32m~/Documents/School/T2Y4/SENG474/Project/474CommitML/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/School/T2Y4/SENG474/Project/474CommitML/.venv/lib/python3.10/site-packages/gradient_accumulator/accumulators.py:46\u001b[0m, in \u001b[0;36mGradientAccumulateModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m# Gradient Tape\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> 46\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)  \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39m# Compute the loss value.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39m# The loss function is configured in `compile()`.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(\n\u001b[1;32m     51\u001b[0m         y,\n\u001b[1;32m     52\u001b[0m         y_pred,\n\u001b[1;32m     53\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m     54\u001b[0m         regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses,\n\u001b[1;32m     55\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"gradient_accumulate_model\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(256, 16), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "output_types = (tf.float32, tf.float32)\n",
    "output_shapes = ((256, 16), (256, 16))\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    unlabelled_generator,\n",
    "    output_types=output_types,\n",
    "    output_shapes=output_shapes,\n",
    ")\n",
    "\n",
    "batch_size = 10\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "#print(len(list(dataset.as_numpy_iterator())))\n",
    "# Use the dataset in the fit function\n",
    "model = CommitDiffModel(unsupervised_data_size = 100)\n",
    "model.initialize(encoder=0)\n",
    "model.fit_siam_generator(dataset, epochs=8, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoder in tqdm([0,1,5,4,2,3]):\n",
    "    try:\n",
    "        model = CommitDiffModel(unsupervised_data_size = len(X_train_unsupervised))\n",
    "        model.initialize(encoder=encoder)\n",
    "        model.fit_siam(np.array(X_train_unsupervised), epochs=8, verbose=1)\n",
    "        model.fit_binary_classification(X_train, np.array(y_train), epochs=8, batch_size=4, verbose=1)\n",
    "        score = model.evaluate_binary_classification(X_test, np.array(y_test), verbose=0)\n",
    "        print(\"Enocder:\", encoder)\n",
    "        print(\"Score:\", score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"------------------------------------------\")\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
