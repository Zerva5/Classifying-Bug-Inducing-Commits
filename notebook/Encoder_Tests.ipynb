{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['OMP_NUM_THREADS'] = '3' \n",
    "os.environ['KMP_BLOCKTIME'] = '1'\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "from dataset import get_labelled, get_unlabelled, _preload, _unload\n",
    "from Commit import CommitFactory\n",
    "from Model import CommitDiffModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### META PARAMS #####\n",
    "\n",
    "#Size / depth / length of each individual context/path\n",
    "CONTEXT_SIZE = 8\n",
    "\n",
    "#Total number of contexts to sample per bag\n",
    "BAG_SIZE = 256\n",
    "\n",
    "#Size of fixed length vector to encode to\n",
    "OUTPUT_SIZE = 256\n",
    "\n",
    "# Hard limit to filter bags by. Bags which exceed this size won't even be sampled.\n",
    "# Set to None to turn off\n",
    "MAX_BAG_SIZE_FILTER = 2048 * 4\n",
    "\n",
    "#Maximum number of labelled commits to train on\n",
    "MAX_LABELLED_COMMITS = 4096 * 8\n",
    "\n",
    "#Maximum number of unlabelled commits to train on\n",
    "MAX_UNLABELLED_COMMITS = 4096 * 8\n",
    "\n",
    "#Batch size for unsupervised training. Higher = faster/better but more memory required\n",
    "SIAM_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commit = CommitFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)\n",
    "CommitDiffModel = CommitDiffModelFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE, OUTPUT_SIZE=OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Commit lookup table\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197ee2781ce844498a4bf7c4aebca3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading commit lookups:   0%|          | 0/32768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../data/commit_lookups/labelled/01_priority_commit_lookups.pickle\n",
      "Appending pickle of length: 7549 , new dict length: 6906\n",
      "Loading file ../data/commit_lookups/labelled/02_priority_commit_lookups.pickle\n",
      "Appending pickle of length: 10410 , new dict length: 9517\n",
      "Loading file ../data/commit_lookups/labelled/03_priority_commit_lookups.pickle\n",
      "Appending pickle of length: 7246 , new dict length: 12646\n"
     ]
    }
   ],
   "source": [
    "_preload(max_commit_bag_size = MAX_BAG_SIZE_FILTER, max_commits = MAX_LABELLED_COMMITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec35a6c3994c429bc743bff8bef9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating apache_positive_pairs X_train and y_train:   0%|          | 0/2264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29ebcc294984bfe9448efb5b2ee1f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating apache_negative_pairs X_train and y_train:   0%|          | 0/9511 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_labelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea778663abe4f81befc0f8455b40765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Unsupervised X_train:   0%|          | 0/12646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_unsupervised = get_unlabelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size 3622\n",
      "Train set split 0.507454445057979\n",
      "Test set size 906\n",
      "Test set split 0.47019867549668876\n",
      "Unsupervised Train Size 12646\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size\", len(y_train))\n",
    "print(\"Train set split\", np.sum(y_train)/len(y_train))\n",
    "print(\"Test set size\", len(y_test))\n",
    "print(\"Test set split\", np.sum(y_test)/len(y_test))\n",
    "print(\"Unsupervised Train Size\", len(X_train_unsupervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "99/99 [==============================] - 36s 361ms/step - loss: -0.2507\n",
      "Epoch 2/16\n",
      "99/99 [==============================] - 35s 353ms/step - loss: -0.4604\n",
      "Epoch 3/16\n",
      "99/99 [==============================] - 36s 362ms/step - loss: -0.5127\n",
      "Epoch 4/16\n",
      "99/99 [==============================] - 36s 359ms/step - loss: -0.5119\n",
      "Epoch 5/16\n",
      "99/99 [==============================] - 36s 360ms/step - loss: -0.5064\n",
      "Epoch 6/16\n",
      "99/99 [==============================] - 37s 369ms/step - loss: -0.5047\n",
      "Epoch 7/16\n",
      "99/99 [==============================] - 36s 365ms/step - loss: -0.5059\n",
      "Epoch 8/16\n",
      "99/99 [==============================] - 36s 361ms/step - loss: -0.5152\n",
      "Epoch 9/16\n",
      "99/99 [==============================] - 36s 361ms/step - loss: -0.5230\n",
      "Epoch 10/16\n",
      "99/99 [==============================] - 36s 362ms/step - loss: -0.5233\n",
      "Epoch 11/16\n",
      "99/99 [==============================] - 36s 361ms/step - loss: -0.5223\n",
      "Epoch 12/16\n",
      "99/99 [==============================] - 36s 360ms/step - loss: -0.5236\n",
      "Epoch 13/16\n",
      "99/99 [==============================] - 36s 359ms/step - loss: -0.5262\n",
      "Epoch 14/16\n",
      "99/99 [==============================] - 36s 362ms/step - loss: -0.5286\n",
      "Epoch 15/16\n",
      "99/99 [==============================] - 35s 354ms/step - loss: -0.5295\n",
      "Epoch 16/16\n",
      "99/99 [==============================] - 37s 373ms/step - loss: -0.5303\n",
      "Epoch 1/16\n",
      "57/57 [==============================] - 8s 117ms/step - loss: 0.7088\n",
      "Epoch 2/16\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 0.6947\n",
      "Epoch 3/16\n",
      "57/57 [==============================] - 7s 122ms/step - loss: 0.6611\n",
      "Epoch 4/16\n",
      "57/57 [==============================] - 7s 124ms/step - loss: 0.5471\n",
      "Epoch 5/16\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 0.4853\n",
      "Epoch 6/16\n",
      "57/57 [==============================] - 7s 120ms/step - loss: 0.4793\n",
      "Epoch 7/16\n",
      "57/57 [==============================] - 7s 118ms/step - loss: 0.4691\n",
      "Epoch 8/16\n",
      "57/57 [==============================] - 7s 121ms/step - loss: 0.4541\n",
      "Epoch 9/16\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 0.4479\n",
      "Epoch 10/16\n",
      "57/57 [==============================] - 7s 118ms/step - loss: 0.4581\n",
      "Epoch 11/16\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 0.4318\n",
      "Epoch 12/16\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 0.4354\n",
      "Epoch 13/16\n",
      "57/57 [==============================] - 9s 163ms/step - loss: 0.4060\n",
      "Epoch 14/16\n",
      "57/57 [==============================] - 11s 192ms/step - loss: 0.4122\n",
      "Epoch 15/16\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.4047\n",
      "Epoch 16/16\n",
      "57/57 [==============================] - 7s 120ms/step - loss: 0.3951\n",
      "Enocder: 5\n",
      "Score: 0.5056589841842651\n",
      "------------------------------------------\n",
      "Epoch 1/16\n",
      "99/99 [==============================] - 77s 783ms/step - loss: -0.3274\n",
      "Epoch 2/16\n",
      "99/99 [==============================] - 76s 772ms/step - loss: -0.4696\n",
      "Epoch 3/16\n",
      "99/99 [==============================] - 65s 657ms/step - loss: -0.4841\n",
      "Epoch 4/16\n",
      "99/99 [==============================] - 60s 605ms/step - loss: -0.5002\n",
      "Epoch 5/16\n",
      "99/99 [==============================] - 60s 605ms/step - loss: -0.5211\n",
      "Epoch 6/16\n",
      "99/99 [==============================] - 60s 607ms/step - loss: -0.5383\n",
      "Epoch 7/16\n",
      "99/99 [==============================] - 60s 607ms/step - loss: -0.5487\n",
      "Epoch 8/16\n",
      "99/99 [==============================] - 60s 606ms/step - loss: -0.5493\n",
      "Epoch 9/16\n",
      "99/99 [==============================] - 60s 607ms/step - loss: -0.5481\n",
      "Epoch 10/16\n",
      "99/99 [==============================] - 60s 605ms/step - loss: -0.5505\n",
      "Epoch 11/16\n",
      "99/99 [==============================] - 60s 606ms/step - loss: -0.5535\n",
      "Epoch 12/16\n",
      "99/99 [==============================] - 60s 608ms/step - loss: -0.5530\n",
      "Epoch 13/16\n",
      "99/99 [==============================] - 60s 606ms/step - loss: -0.5525\n",
      "Epoch 14/16\n",
      "99/99 [==============================] - 60s 608ms/step - loss: -0.5539\n",
      "Epoch 15/16\n",
      "99/99 [==============================] - 60s 604ms/step - loss: -0.5553\n",
      "Epoch 16/16\n",
      "99/99 [==============================] - 58s 582ms/step - loss: -0.5560\n",
      "Epoch 1/16\n",
      "57/57 [==============================] - 15s 242ms/step - loss: 0.7078\n",
      "Epoch 2/16\n",
      "57/57 [==============================] - 14s 242ms/step - loss: 0.6875\n",
      "Epoch 3/16\n",
      "57/57 [==============================] - 14s 241ms/step - loss: 0.6248\n",
      "Epoch 4/16\n",
      "57/57 [==============================] - 14s 243ms/step - loss: 0.5126\n",
      "Epoch 5/16\n",
      "57/57 [==============================] - 14s 240ms/step - loss: 0.4772\n",
      "Epoch 6/16\n",
      "57/57 [==============================] - 14s 241ms/step - loss: 0.4882\n",
      "Epoch 7/16\n",
      "57/57 [==============================] - 13s 233ms/step - loss: 0.4587\n",
      "Epoch 8/16\n",
      "57/57 [==============================] - 13s 232ms/step - loss: 0.4750\n",
      "Epoch 9/16\n",
      "57/57 [==============================] - 13s 235ms/step - loss: 0.4461\n",
      "Epoch 10/16\n",
      "57/57 [==============================] - 13s 230ms/step - loss: 0.4321\n",
      "Epoch 11/16\n",
      "57/57 [==============================] - 13s 232ms/step - loss: 0.4508\n",
      "Epoch 12/16\n",
      "57/57 [==============================] - 13s 234ms/step - loss: 0.4281\n",
      "Epoch 13/16\n",
      "57/57 [==============================] - 13s 236ms/step - loss: 0.4289\n",
      "Epoch 14/16\n",
      "57/57 [==============================] - 13s 231ms/step - loss: 0.4149\n",
      "Epoch 15/16\n",
      "57/57 [==============================] - 13s 233ms/step - loss: 0.4227\n",
      "Epoch 16/16\n",
      "57/57 [==============================] - 13s 231ms/step - loss: 0.4099\n",
      "Enocder: 4\n",
      "Score: 0.5059818029403687\n",
      "------------------------------------------\n",
      "Epoch 1/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.3550\n",
      "Epoch 2/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4025\n",
      "Epoch 3/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4334\n",
      "Epoch 4/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4649\n",
      "Epoch 5/16\n",
      "99/99 [==============================] - 136s 1s/step - loss: -0.4760\n",
      "Epoch 6/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4801\n",
      "Epoch 7/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4827\n",
      "Epoch 8/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4839\n",
      "Epoch 9/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4836\n",
      "Epoch 10/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4878\n",
      "Epoch 11/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4926\n",
      "Epoch 12/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4953\n",
      "Epoch 13/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.4994\n",
      "Epoch 14/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.5032\n",
      "Epoch 15/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.5038\n",
      "Epoch 16/16\n",
      "99/99 [==============================] - 135s 1s/step - loss: -0.5036\n",
      "Epoch 1/16\n",
      "57/57 [==============================] - 29s 480ms/step - loss: 0.7081\n",
      "Epoch 2/16\n",
      "57/57 [==============================] - 27s 469ms/step - loss: 0.6893\n",
      "Epoch 3/16\n",
      "57/57 [==============================] - 26s 460ms/step - loss: 0.6441\n",
      "Epoch 4/16\n",
      "57/57 [==============================] - 27s 470ms/step - loss: 0.5170\n",
      "Epoch 5/16\n",
      "57/57 [==============================] - 27s 471ms/step - loss: 0.5022\n",
      "Epoch 6/16\n",
      "57/57 [==============================] - 27s 465ms/step - loss: 0.4624\n",
      "Epoch 7/16\n",
      "57/57 [==============================] - 27s 479ms/step - loss: 0.4657\n",
      "Epoch 8/16\n",
      "57/57 [==============================] - 27s 466ms/step - loss: 0.4496\n",
      "Epoch 9/16\n",
      "57/57 [==============================] - 27s 466ms/step - loss: 0.4469\n",
      "Epoch 10/16\n",
      "57/57 [==============================] - 27s 468ms/step - loss: 0.4570\n",
      "Epoch 11/16\n",
      "57/57 [==============================] - 27s 482ms/step - loss: 0.4361\n",
      "Epoch 12/16\n",
      "57/57 [==============================] - 27s 472ms/step - loss: 0.4253\n",
      "Epoch 13/16\n",
      "57/57 [==============================] - 27s 472ms/step - loss: 0.4301\n",
      "Epoch 14/16\n",
      "57/57 [==============================] - 27s 470ms/step - loss: 0.4262\n",
      "Epoch 15/16\n",
      "57/57 [==============================] - 27s 474ms/step - loss: 0.4290\n",
      "Epoch 16/16\n",
      "57/57 [==============================] - 27s 480ms/step - loss: 0.4072\n",
      "Enocder: 2\n",
      "Score: 0.5189882516860962\n",
      "------------------------------------------\n",
      "Epoch 1/16\n",
      "99/99 [==============================] - 167s 2s/step - loss: -0.2547\n",
      "Epoch 2/16\n",
      "99/99 [==============================] - 170s 2s/step - loss: -0.3539\n",
      "Epoch 3/16\n",
      "99/99 [==============================] - 216s 2s/step - loss: -0.4062\n",
      "Epoch 4/16\n",
      "99/99 [==============================] - 198s 2s/step - loss: -0.4189\n",
      "Epoch 5/16\n",
      "99/99 [==============================] - 173s 2s/step - loss: -0.4238\n",
      "Epoch 6/16\n",
      "99/99 [==============================] - 177s 2s/step - loss: -0.4292\n",
      "Epoch 7/16\n",
      "99/99 [==============================] - 175s 2s/step - loss: -0.4332\n",
      "Epoch 8/16\n",
      "99/99 [==============================] - 176s 2s/step - loss: -0.4392\n",
      "Epoch 9/16\n",
      "99/99 [==============================] - 176s 2s/step - loss: -0.4483\n",
      "Epoch 10/16\n",
      "99/99 [==============================] - 176s 2s/step - loss: -0.4559\n",
      "Epoch 11/16\n",
      "99/99 [==============================] - 176s 2s/step - loss: -0.4597\n",
      "Epoch 12/16\n",
      "99/99 [==============================] - 180s 2s/step - loss: -0.4625\n",
      "Epoch 13/16\n",
      "99/99 [==============================] - 174s 2s/step - loss: -0.4633\n",
      "Epoch 14/16\n",
      "99/99 [==============================] - 179s 2s/step - loss: -0.4638\n",
      "Epoch 15/16\n",
      "99/99 [==============================] - 170s 2s/step - loss: -0.4641\n",
      "Epoch 16/16\n",
      "99/99 [==============================] - 172s 2s/step - loss: -0.4671\n",
      "Epoch 1/16\n",
      "57/57 [==============================] - 37s 523ms/step - loss: 0.7184\n",
      "Epoch 2/16\n",
      "57/57 [==============================] - 31s 545ms/step - loss: 0.6874\n",
      "Epoch 3/16\n",
      "57/57 [==============================] - 31s 546ms/step - loss: 0.6847\n",
      "Epoch 4/16\n",
      "57/57 [==============================] - 31s 546ms/step - loss: 0.6027\n",
      "Epoch 5/16\n",
      "57/57 [==============================] - 31s 535ms/step - loss: 0.5053\n",
      "Epoch 6/16\n",
      "57/57 [==============================] - 31s 536ms/step - loss: 0.4890\n",
      "Epoch 7/16\n",
      "57/57 [==============================] - 31s 549ms/step - loss: 0.4766\n",
      "Epoch 8/16\n",
      "57/57 [==============================] - 31s 550ms/step - loss: 0.4552\n",
      "Epoch 9/16\n",
      "57/57 [==============================] - 31s 550ms/step - loss: 0.4662\n",
      "Epoch 10/16\n",
      "57/57 [==============================] - 32s 565ms/step - loss: 0.4388\n",
      "Epoch 11/16\n",
      "57/57 [==============================] - 33s 573ms/step - loss: 0.4351\n",
      "Epoch 12/16\n",
      "57/57 [==============================] - 32s 561ms/step - loss: 0.4320\n",
      "Epoch 13/16\n",
      "57/57 [==============================] - 32s 559ms/step - loss: 0.4285\n",
      "Epoch 14/16\n",
      "57/57 [==============================] - 31s 540ms/step - loss: 0.4278\n",
      "Epoch 15/16\n",
      "57/57 [==============================] - 31s 544ms/step - loss: 0.4265\n",
      "Epoch 16/16\n",
      "57/57 [==============================] - 32s 556ms/step - loss: 0.4274\n",
      "Enocder: 3\n",
      "Score: 0.5815518498420715\n",
      "------------------------------------------\n",
      "Epoch 1/16\n",
      "99/99 [==============================] - 30s 298ms/step - loss: -0.0346\n",
      "Epoch 2/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.0943\n",
      "Epoch 3/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.1640\n",
      "Epoch 4/16\n",
      "99/99 [==============================] - 29s 290ms/step - loss: -0.2338\n",
      "Epoch 5/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.2952\n",
      "Epoch 6/16\n",
      "99/99 [==============================] - 30s 298ms/step - loss: -0.3482\n",
      "Epoch 7/16\n",
      "99/99 [==============================] - 29s 296ms/step - loss: -0.3936\n",
      "Epoch 8/16\n",
      "99/99 [==============================] - 30s 297ms/step - loss: -0.4316\n",
      "Epoch 9/16\n",
      "99/99 [==============================] - 30s 298ms/step - loss: -0.4623\n",
      "Epoch 10/16\n",
      "99/99 [==============================] - 29s 290ms/step - loss: -0.4865\n",
      "Epoch 11/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.5056\n",
      "Epoch 12/16\n",
      "99/99 [==============================] - 29s 293ms/step - loss: -0.5208\n",
      "Epoch 13/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.5326\n",
      "Epoch 14/16\n",
      "99/99 [==============================] - 29s 290ms/step - loss: -0.5421\n",
      "Epoch 15/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.5498\n",
      "Epoch 16/16\n",
      "99/99 [==============================] - 29s 291ms/step - loss: -0.5559\n",
      "Epoch 1/16\n",
      "57/57 [==============================] - 6s 42ms/step - loss: 0.7234\n",
      "Epoch 2/16\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.6952\n",
      "Epoch 3/16\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6903\n",
      "Epoch 4/16\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 0.6713\n",
      "Epoch 5/16\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.6025\n",
      "Epoch 6/16\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.5148\n",
      "Epoch 7/16\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.4869\n",
      "Epoch 8/16\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4876\n",
      "Epoch 9/16\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 0.4754\n",
      "Epoch 10/16\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.4693\n",
      "Epoch 11/16\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.4688\n",
      "Epoch 12/16\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.4682\n",
      "Epoch 13/16\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.4714\n",
      "Epoch 14/16\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 0.4623\n",
      "Epoch 15/16\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.4696\n",
      "Epoch 16/16\n",
      "57/57 [==============================] - 2s 40ms/step - loss: 0.4608\n",
      "Enocder: 0\n",
      "Score: 0.4795270562171936\n",
      "------------------------------------------\n",
      "Epoch 1/16\n",
      "99/99 [==============================] - 248s 3s/step - loss: -0.2684\n",
      "Epoch 2/16\n",
      "99/99 [==============================] - 248s 3s/step - loss: -0.3662\n",
      "Epoch 3/16\n",
      "99/99 [==============================] - 248s 3s/step - loss: -0.3759\n",
      "Epoch 4/16\n",
      "99/99 [==============================] - 248s 3s/step - loss: -0.3821\n",
      "Epoch 5/16\n",
      "99/99 [==============================] - 248s 2s/step - loss: -0.4005\n",
      "Epoch 6/16\n",
      "99/99 [==============================] - 248s 2s/step - loss: -0.4113\n",
      "Epoch 7/16\n",
      "99/99 [==============================] - 247s 2s/step - loss: -0.4228\n",
      "Epoch 8/16\n",
      "99/99 [==============================] - 251s 3s/step - loss: -0.4402\n",
      "Epoch 9/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.4576\n",
      "Epoch 10/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.4670\n",
      "Epoch 11/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.4739\n",
      "Epoch 12/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.4825\n",
      "Epoch 13/16\n",
      "99/99 [==============================] - 248s 3s/step - loss: -0.4903\n",
      "Epoch 14/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.4976\n",
      "Epoch 15/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.5027\n",
      "Epoch 16/16\n",
      "99/99 [==============================] - 249s 3s/step - loss: -0.5060\n",
      "Epoch 1/16\n",
      "57/57 [==============================] - 50s 804ms/step - loss: 0.7290\n",
      "Epoch 2/16\n",
      "57/57 [==============================] - 46s 805ms/step - loss: 0.6978\n",
      "Epoch 3/16\n",
      "57/57 [==============================] - 46s 805ms/step - loss: 0.6825\n",
      "Epoch 4/16\n",
      "57/57 [==============================] - 46s 804ms/step - loss: 0.6322\n",
      "Epoch 5/16\n",
      "57/57 [==============================] - 46s 804ms/step - loss: 0.5020\n",
      "Epoch 6/16\n",
      "57/57 [==============================] - 46s 804ms/step - loss: 0.4347\n",
      "Epoch 7/16\n",
      "57/57 [==============================] - 46s 807ms/step - loss: 0.3573\n",
      "Epoch 8/16\n",
      "57/57 [==============================] - 46s 809ms/step - loss: 0.3208\n",
      "Epoch 9/16\n",
      "57/57 [==============================] - 46s 805ms/step - loss: 0.2926\n",
      "Epoch 10/16\n",
      "57/57 [==============================] - 46s 805ms/step - loss: 0.2544\n",
      "Epoch 11/16\n",
      "57/57 [==============================] - 46s 805ms/step - loss: 0.2175\n",
      "Epoch 12/16\n",
      "57/57 [==============================] - 46s 807ms/step - loss: 0.2157\n",
      "Epoch 13/16\n",
      "57/57 [==============================] - 46s 806ms/step - loss: 0.1961\n",
      "Epoch 14/16\n",
      "57/57 [==============================] - 46s 806ms/step - loss: 0.1854\n",
      "Epoch 15/16\n",
      "57/57 [==============================] - 46s 807ms/step - loss: 0.1865\n",
      "Epoch 16/16\n",
      "57/57 [==============================] - 46s 804ms/step - loss: 0.1889\n",
      "Enocder: 1\n",
      "Score: 0.8828353881835938\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for encoder in tqdm([5,4,2,3,0,1]):\n",
    "    try:\n",
    "        model = CommitDiffModel(unsupervised_data_size = len(X_train_unsupervised), siam_batch_size = SIAM_BATCH_SIZE)\n",
    "        model.initialize(encoder=encoder)\n",
    "        model.fit_siam(np.array(X_train_unsupervised), epochs=16, verbose=1)\n",
    "        model.fit_binary_classification(X_train, np.array(y_train), epochs=16, batch_size=64, verbose=1)\n",
    "        score = model.evaluate_binary_classification(X_test, np.array(y_test), verbose=0)\n",
    "        print(\"Enocder:\", encoder)\n",
    "        print(\"Score:\", score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"------------------------------------------\")\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
