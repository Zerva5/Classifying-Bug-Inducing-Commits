{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07c3c7f-e184-4c8f-af85-aea0e6c732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83cce296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Commit import CommitFactory\n",
    "Commit = CommitFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6ea281",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = pd.read_csv(\"../data/all_apache_commits.csv\")\n",
    "\n",
    "RAW_DATA = RAW_DATA.loc[RAW_DATA['diff_line_count'] <= 50]\n",
    "RAW_DATA = RAW_DATA.loc[RAW_DATA['files_changed'] <= 8]\n",
    "\n",
    "REPO_LOOKUP = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = set(list(RAW_DATA[\"repo\"]))\n",
    "\n",
    "#Create a \"clones\" directory in order to clone local repos\n",
    "if not os.path.exists(\"../clones\"):\n",
    "    os.makedirs(\"../clones\")\n",
    "\n",
    "# Clone each \"repo\" into the \"clones\" folder\n",
    "for repo in tqdm(repos):\n",
    "    if not os.path.exists(f\"../clones/{repo}\"):\n",
    "        os.system(f\"git clone https://github.com/{repo.replace('-', '/')}.git ../clones/{repo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c3e100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total commits found 266493\n"
     ]
    }
   ],
   "source": [
    "print(\"Total commits found\", len(RAW_DATA))\n",
    "DATA_SLICE = [0,100]\n",
    "\n",
    "RAW_DATA_SLICE = RAW_DATA.iloc[DATA_SLICE[0]: DATA_SLICE[1]]\n",
    "\n",
    "TUPLES = [(row['sha'], row['repo']) for i, row in RAW_DATA_SLICE.iterrows()]\n",
    "TUPLES = list(set(TUPLES))\n",
    "\n",
    "#Creates a lookup dictionary where any commit SHA can be looked up to grab the Commit object with all the data, + bag of paths\n",
    "COMMIT_DATA_LOOKUP = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c1d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_errors(e):\n",
    "    print(\"BIG ERROR, WE SHOULD NEVER GET HERE\", e)\n",
    "    return None\n",
    "\n",
    "def _to_commit_mp(pair):\n",
    "    try:\n",
    "        sha = pair[0]\n",
    "        repo = pair[1]\n",
    "\n",
    "        commit = Commit(sha, f\"../clones/{repo}\")\n",
    "        commit._populate_commit_info()  \n",
    "        commit._generate_bags_of_contexts()\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "\n",
    "    return commit\n",
    "\n",
    "def create_lookup_mp(pairs, data_slice):\n",
    "    results = []\n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=8)\n",
    "\n",
    "    print(\"APPENDING JOBS...\")\n",
    "    for pair in pairs:\n",
    "        #print(pair)\n",
    "        result = pool.apply_async(_to_commit_mp, args=(pair,), error_callback=_handle_errors)\n",
    "        results.append(result)\n",
    "\n",
    "    print(\"FINISHED APPENDING JOBS\")\n",
    "\n",
    "    # Wait for all jobs to finish and collect the results\n",
    "    final_results = {}\n",
    "    errorList = []\n",
    "    num_finished = 0\n",
    "    num_errors = 0\n",
    "    num_saved = 0\n",
    "    save_step = 10\n",
    "    for i, result in tqdm(enumerate(results), desc=\"Processing commit\", total=len(results)):\n",
    "        c = result.get()\n",
    "        if type(c) == str:\n",
    "            print(\"error in pool job\",i,\":\", c)\n",
    "            num_errors += 1\n",
    "            errorList.append(pairs[i])\n",
    "        else:\n",
    "            final_results[c.sha] = c\n",
    "\n",
    "            ## Need to save the subslice to a pickle and clear final_results\n",
    "            if(num_finished == save_step):\n",
    "                \n",
    "                \n",
    "                with open('../data/commit_lookups/commit_data_lookup' +\n",
    "                          str(DATA_SLICE[0] + (save_step * (num_saved))) + \"-\" + str(DATA_SLICE[0] + (save_step * (num_saved + 1))) +\n",
    "                          '.pickle', 'wb') as file:\n",
    "                    pickle.dump(final_results, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                final_results = {}\n",
    "\n",
    "                num_saved += 1\n",
    "                num_finished = 0\n",
    "\n",
    "                \n",
    "                \n",
    "            \n",
    "        num_finished += 1   \n",
    "\n",
    "    \n",
    "    with open('../data/commit_lookups/commit_data_lookup' +\n",
    "              str(DATA_SLICE[0] + (save_step * (num_saved))) + \"-\" + str(DATA_SLICE[1]) +\n",
    "              '.pickle', 'wb') as file:\n",
    "        pickle.dump(final_results, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "    pool.close()\n",
    "    return final_results\n",
    "\n",
    "COMMIT_DATA_LOOKUP = create_lookup_mp(TUPLES, DATA_SLICE)\n",
    "print(\"DONE PROCESING COMMITS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
