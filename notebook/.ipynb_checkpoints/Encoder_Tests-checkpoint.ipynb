{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['OMP_NUM_THREADS'] = '3' \n",
    "os.environ['KMP_BLOCKTIME'] = '1'\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "from dataset import get_labelled, get_unlabelled, _preload, _unload\n",
    "from Commit import CommitFactory\n",
    "from Model import CommitDiffModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### META PARAMS #####\n",
    "\n",
    "#Size / depth / length of each individual context/path\n",
    "CONTEXT_SIZE = 16\n",
    "\n",
    "#Total number of contexts to sample per bag\n",
    "BAG_SIZE = 256\n",
    "\n",
    "#Size of fixed length vector to encode to\n",
    "OUTPUT_SIZE = 512\n",
    "\n",
    "# Hard limit to filter bags by. Bags which exceed this size won't even be sampled.\n",
    "# Set to None to turn off\n",
    "MAX_BAG_SIZE_FILTER = 2048\n",
    "\n",
    "#Maximum number of labelled commits to train on\n",
    "MAX_LABELLED_COMMITS = 512\n",
    "\n",
    "#Maximum number of unlabelled commits to train on\n",
    "MAX_UNLABELLED_COMMITS = 512\n",
    "\n",
    "#Batch size for unsupervised training. Higher = faster/better but more memory required\n",
    "SIAM_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commit = CommitFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)\n",
    "CommitDiffModel = CommitDiffModelFactory(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE, OUTPUT_SIZE=OUTPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Commit lookup table\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c98841a1a274fe287a3f133a10eef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading commit lookups:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ../data/commit_lookups/labelled/01_priority_commit_lookups.pickle\n"
     ]
    }
   ],
   "source": [
    "_preload(max_commit_bag_size = MAX_BAG_SIZE_FILTER, max_commits = MAX_LABELLED_COMMITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75395491d534c22ae64166d5e924a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating apache_positive_pairs X_train and y_train:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a8d64d6bcc466c9b32cb0c266038c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating apache_negative_pairs X_train and y_train:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_labelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b2851ec62b43cc8b74b6280465e1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Unsupervised X_train:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_unsupervised = get_unlabelled(BAG_SIZE=BAG_SIZE, CONTEXT_SIZE=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size 27\n",
      "Train set split 0.4444444444444444\n",
      "Test set size 7\n",
      "Test set split 0.7142857142857143\n",
      "Unsupervised Train Size 1024\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size\", len(y_train))\n",
    "print(\"Train set split\", np.sum(y_train)/len(y_train))\n",
    "print(\"Test set size\", len(y_test))\n",
    "print(\"Test set split\", np.sum(y_test)/len(y_test))\n",
    "print(\"Unsupervised Train Size\", len(X_train_unsupervised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134df222d94f4aa388cb39c1b0518024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "16/16 [==============================] - 6s 376ms/step - loss: 0.0124\n",
      "Epoch 2/8\n",
      "16/16 [==============================] - 6s 379ms/step - loss: -0.0247\n",
      "Epoch 3/8\n",
      "16/16 [==============================] - 7s 404ms/step - loss: -0.0747\n",
      "Epoch 4/8\n",
      "11/16 [===================>..........] - ETA: 2s - loss: -0.1248"
     ]
    }
   ],
   "source": [
    "for encoder in tqdm([5,4,2,3,0,1]):\n",
    "    try:\n",
    "        model = CommitDiffModel(unsupervised_data_size = len(X_train_unsupervised), siam_batch_size = SIAM_BATCH_SIZE)\n",
    "        model.initialize(encoder=encoder)\n",
    "        model.fit_siam(np.array(X_train_unsupervised), epochs=8, verbose=1)\n",
    "        model.fit_binary_classification(X_train, np.array(y_train), epochs=8, batch_size=4, verbose=1)\n",
    "        score = model.evaluate_binary_classification(X_test, np.array(y_test), verbose=0)\n",
    "        print(\"Enocder:\", encoder)\n",
    "        print(\"Score:\", score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"------------------------------------------\")\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
